"""empty message

Revision ID: cd4eec9402a8
Revises: 6f01226d28f2
Create Date: 2025-11-18 21:10:39.604495

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'cd4eec9402a8'
down_revision: Union[str, Sequence[str], None] = '6f01226d28f2'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # op.drop_table('topology')
    # op.drop_table('spatial_ref_sys')
    # op.drop_table('layer')
    op.drop_index(op.f('idx_data_ingestion_runs_started_at'), table_name='data_ingestion_runs')
    op.create_index('idx_data_ingestion_runs_started_at', 'data_ingestion_runs', ['started_at'], unique=False, postgresql_ops={'started_at': 'DESC'})
    op.alter_column('enriched_seeds', 'processed',
               existing_type=sa.BOOLEAN(),
               server_default=None,
               existing_comment='Whether seed has been merged into properties table',
               existing_nullable=False)
    op.drop_index(op.f('idx_lead_score_history_snapshot_date'), table_name='lead_score_history')
    op.create_index('idx_lead_score_history_snapshot_date', 'lead_score_history', ['snapshot_date'], unique=False, postgresql_ops={'snapshot_date': 'DESC'})
    op.add_column('lead_scores', sa.Column('profitability_score', sa.Numeric(precision=5, scale=2), nullable=True, comment='Profitability bucket score (0-100)'))
    op.add_column('lead_scores', sa.Column('profitability_details', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='Detailed profitability metrics (projected_profit, roi, etc)'))
    op.add_column('lead_scores', sa.Column('ml_risk_score', sa.Numeric(precision=5, scale=4), nullable=True, comment='Composite risk score (0-1)'))
    op.add_column('lead_scores', sa.Column('ml_risk_tier', sa.String(length=1), nullable=True, comment='Risk tier (A/B/C/D)'))
    op.add_column('lead_scores', sa.Column('ml_cluster_id', sa.Integer(), nullable=True, comment='Unsupervised cluster ID'))
    op.add_column('lead_scores', sa.Column('ml_anomaly_score', sa.Numeric(precision=10, scale=4), nullable=True, comment='Anomaly detection score'))
    op.alter_column('lead_scores', 'priority_flag',
               existing_type=sa.BOOLEAN(),
               server_default=None,
               existing_comment='High priority flag from ML/hybrid scoring',
               existing_nullable=True)
    op.drop_index(op.f('idx_lead_scores_ml_probability'), table_name='lead_scores')
    op.drop_index(op.f('idx_lead_scores_priority_flag'), table_name='lead_scores')
    op.drop_index(op.f('idx_lead_scores_total_score'), table_name='lead_scores')
    op.create_index('idx_lead_scores_total_score', 'lead_scores', ['total_score'], unique=False, postgresql_ops={'total_score': 'DESC'})
    op.create_index('idx_lead_scores_tier_score', 'lead_scores', ['tier', 'total_score'], unique=False, postgresql_ops={'total_score': 'DESC'})
    op.add_column('ml_feature_store', sa.Column('max_violation_severity', sa.Numeric(precision=5, scale=2), nullable=True, comment='Maximum violation severity score'))
    op.add_column('ml_feature_store', sa.Column('total_market_value', sa.Numeric(precision=12, scale=2), nullable=True, comment='Total market value'))
    op.add_column('ml_feature_store', sa.Column('tax_rate', sa.Numeric(precision=6, scale=4), nullable=True, comment='Property tax rate'))
    op.add_column('ml_feature_store', sa.Column('days_to_tax_sale', sa.Integer(), nullable=True, comment='Days until tax sale'))
    op.add_column('ml_feature_store', sa.Column('nearby_violations_count', sa.Integer(), nullable=True, comment='Number of nearby violations (geo radius)'))
    op.add_column('ml_feature_store', sa.Column('nearest_violation_distance', sa.Numeric(precision=8, scale=4), nullable=True, comment='Distance to nearest violation in miles'))
    op.add_column('ml_feature_store', sa.Column('actual_distress_outcome', sa.Boolean(), nullable=True, comment='Did this property actually experience distress event'))
    op.add_column('ml_feature_store', sa.Column('actual_sale_price', sa.Numeric(precision=12, scale=2), nullable=True, comment='Actual sale price if sold'))
    op.add_column('ml_feature_store', sa.Column('label_date', sa.Date(), nullable=True, comment='Date when label was recorded'))
    op.alter_column('ml_feature_store', 'parcel_id_normalized',
               existing_type=sa.VARCHAR(length=50),
               comment='Normalized parcel ID',
               existing_comment='Normalized parcel ID (digits only)',
               existing_nullable=False)
    op.alter_column('ml_feature_store', 'computed_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When features were computed',
               existing_comment='When features were last computed',
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('ml_feature_store', 'violation_count',
               existing_type=sa.INTEGER(),
               comment='Total number of violations',
               existing_comment='Number of code violations',
               existing_nullable=True)
    op.alter_column('ml_feature_store', 'open_violation_count',
               existing_type=sa.INTEGER(),
               comment='Number of open/active violations',
               existing_comment='Number of open violations',
               existing_nullable=True)
    op.alter_column('ml_feature_store', 'equity_percent',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               type_=sa.Numeric(precision=6, scale=2),
               existing_comment='Equity percentage',
               existing_nullable=True)
    op.alter_column('ml_feature_store', 'property_age_years',
               existing_type=sa.INTEGER(),
               comment='Property age in years',
               existing_comment='Age of property in years',
               existing_nullable=True)
    op.alter_column('ml_feature_store', 'seed_type_tax_sale',
               existing_type=sa.BOOLEAN(),
               server_default=None,
               comment='Is tax sale seed',
               existing_nullable=False)
    op.alter_column('ml_feature_store', 'seed_type_foreclosure',
               existing_type=sa.BOOLEAN(),
               server_default=None,
               comment='Is foreclosure seed',
               existing_nullable=False)
    op.alter_column('ml_feature_store', 'seed_type_code_violation',
               existing_type=sa.BOOLEAN(),
               server_default=None,
               comment='Is code violation seed',
               existing_nullable=False)
    op.drop_index(op.f('idx_ml_feature_store_computed_at'), table_name='ml_feature_store')
    op.drop_index(op.f('idx_ml_feature_store_parcel'), table_name='ml_feature_store')
    op.drop_constraint(op.f('ml_feature_store_parcel_id_normalized_key'), 'ml_feature_store', type_='unique')
    op.create_index('idx_ml_features_computed_at', 'ml_feature_store', ['computed_at'], unique=False)
    op.create_index('idx_ml_features_has_outcome', 'ml_feature_store', ['actual_distress_outcome'], unique=False)
    op.create_index('idx_ml_features_parcel', 'ml_feature_store', ['parcel_id_normalized'], unique=False)
    op.create_unique_constraint('uq_ml_features_parcel_time', 'ml_feature_store', ['parcel_id_normalized', 'computed_at'])
    op.drop_column('ml_feature_store', 'taxes')
    op.drop_column('ml_feature_store', 'tax_sale_deed_status')
    op.drop_column('ml_feature_store', 'has_tax_sale')
    op.drop_column('ml_feature_store', 'distress_score')
    op.drop_column('ml_feature_store', 'equity_risk_ratio')
    op.drop_column('ml_feature_store', 'living_area')
    op.drop_column('ml_feature_store', 'total_mkt')
    op.drop_column('ml_feature_store', 'lot_size')
    op.drop_column('ml_feature_store', 'year_built')
    op.drop_column('ml_feature_store', 'nearby_violations')
    op.drop_column('ml_feature_store', 'nearby_open_violations')
    op.add_column('model_registry', sa.Column('training_samples', sa.Integer(), nullable=True, comment='Number of training samples'))
    op.add_column('model_registry', sa.Column('validation_metrics', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='Hold-out validation metrics'))
    op.add_column('model_registry', sa.Column('deprecated_at', sa.DateTime(timezone=True), nullable=True, comment='When model was deprecated'))
    op.add_column('model_registry', sa.Column('description', sa.Text(), nullable=True, comment='Model description and notes'))
    op.add_column('model_registry', sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False, comment='Timestamp when record was created'))
    op.add_column('model_registry', sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False, comment='Timestamp when record was last updated'))
    op.alter_column('model_registry', 'model_name',
               existing_type=sa.VARCHAR(length=100),
               comment='Model name (e.g., distress_classifier, sale_probability)',
               existing_comment='Name of the ML model (e.g., distress_classifier, sale_probability)',
               existing_nullable=False)
    op.alter_column('model_registry', 'version',
               existing_type=sa.VARCHAR(length=50),
               comment='Model version (e.g., v1.0.0, 20241114_120000)',
               existing_comment='Model version identifier (timestamp or semantic version)',
               existing_nullable=False)
    op.alter_column('model_registry', 'artifact_path',
               existing_type=sa.VARCHAR(length=500),
               comment='Path to model artifact file (joblib)',
               existing_comment='Path to model artifact file (joblib/pickle)',
               existing_nullable=False)
    op.alter_column('model_registry', 'training_date',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=None,
               comment='When model was trained',
               existing_comment='When the model was trained',
               existing_nullable=False)
    op.alter_column('model_registry', 'feature_names',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               comment='List of feature names used',
               existing_comment='List of feature names used by the model',
               existing_nullable=True)
    op.alter_column('model_registry', 'hyperparameters',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               comment='Model hyperparameters',
               existing_comment='Model hyperparameters used during training',
               existing_nullable=True)
    op.alter_column('model_registry', 'metrics',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               comment='Training/validation metrics (ROC-AUC, PR-AUC, MAE, etc.)',
               existing_comment='Training and validation metrics',
               existing_nullable=True)
    op.alter_column('model_registry', 'is_active',
               existing_type=sa.BOOLEAN(),
               server_default=None,
               comment='Is this the currently active/deployed model',
               existing_comment='Whether this model version is currently active for inference',
               existing_nullable=False)
    op.alter_column('model_registry', 'promoted_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When model was promoted to production',
               existing_comment='When the model was promoted to production',
               existing_nullable=True)
    op.drop_constraint(op.f('uq_model_registry_name_version'), 'model_registry', type_='unique')
    op.drop_index(op.f('idx_model_registry_active'), table_name='model_registry')
    op.create_index('idx_model_registry_active', 'model_registry', ['is_active'], unique=False)
    op.create_unique_constraint('uq_model_name_version', 'model_registry', ['model_name', 'version'])
    op.drop_column('model_registry', 'notes')
    op.drop_column('model_registry', 'retired_at')
    op.drop_column('model_registry', 'created_by')
    op.alter_column('properties', 'seed_type',
               existing_type=sa.VARCHAR(length=100),
               comment='Comma-separated list of seed types that identified this property',
               existing_comment='Primary seed source(s): tax_sale, code_violation, foreclosure (comma-separated for multi-source)',
               existing_nullable=True)
    op.drop_index(op.f('idx_properties_coordinates'), table_name='properties', postgresql_using='gist')
    op.drop_index(op.f('idx_properties_seed_type'), table_name='properties')
    op.create_index('idx_properties_city', 'properties', ['city'], unique=False)
    op.create_index('idx_properties_is_active', 'properties', ['is_active'], unique=False)
    op.create_index('idx_properties_zip_code', 'properties', ['zip_code'], unique=False)
    op.drop_column('properties', 'coordinates')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('properties', sa.Column('coordinates', geoalchemy2.types.Geography(geometry_type='POINT', srid=4326, dimension=2, from_text='ST_GeogFromText', name='geography', _spatial_index_reflected=True), autoincrement=False, nullable=True, comment='WGS84 coordinates (PostGIS)'))
    op.drop_index('idx_properties_zip_code', table_name='properties')
    op.drop_index('idx_properties_is_active', table_name='properties')
    op.drop_index('idx_properties_city', table_name='properties')
    op.create_index(op.f('idx_properties_seed_type'), 'properties', ['seed_type'], unique=False)
    op.create_index(op.f('idx_properties_coordinates'), 'properties', ['coordinates'], unique=False, postgresql_using='gist')
    op.alter_column('properties', 'seed_type',
               existing_type=sa.VARCHAR(length=100),
               comment='Primary seed source(s): tax_sale, code_violation, foreclosure (comma-separated for multi-source)',
               existing_comment='Comma-separated list of seed types that identified this property',
               existing_nullable=True)
    op.add_column('model_registry', sa.Column('created_by', sa.VARCHAR(length=100), autoincrement=False, nullable=True, comment='User or system that created this model'))
    op.add_column('model_registry', sa.Column('retired_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True, comment='When the model was retired from production'))
    op.add_column('model_registry', sa.Column('notes', sa.TEXT(), autoincrement=False, nullable=True, comment='Additional notes about this model version'))
    op.drop_constraint('uq_model_name_version', 'model_registry', type_='unique')
    op.drop_index('idx_model_registry_active', table_name='model_registry')
    op.create_index(op.f('idx_model_registry_active'), 'model_registry', ['model_name', 'is_active'], unique=False)
    op.create_unique_constraint(op.f('uq_model_registry_name_version'), 'model_registry', ['model_name', 'version'], postgresql_nulls_not_distinct=False)
    op.alter_column('model_registry', 'promoted_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When the model was promoted to production',
               existing_comment='When model was promoted to production',
               existing_nullable=True)
    op.alter_column('model_registry', 'is_active',
               existing_type=sa.BOOLEAN(),
               server_default=sa.text('false'),
               comment='Whether this model version is currently active for inference',
               existing_comment='Is this the currently active/deployed model',
               existing_nullable=False)
    op.alter_column('model_registry', 'metrics',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               comment='Training and validation metrics',
               existing_comment='Training/validation metrics (ROC-AUC, PR-AUC, MAE, etc.)',
               existing_nullable=True)
    op.alter_column('model_registry', 'hyperparameters',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               comment='Model hyperparameters used during training',
               existing_comment='Model hyperparameters',
               existing_nullable=True)
    op.alter_column('model_registry', 'feature_names',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               comment='List of feature names used by the model',
               existing_comment='List of feature names used',
               existing_nullable=True)
    op.alter_column('model_registry', 'training_date',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=sa.text('CURRENT_TIMESTAMP'),
               comment='When the model was trained',
               existing_comment='When model was trained',
               existing_nullable=False)
    op.alter_column('model_registry', 'artifact_path',
               existing_type=sa.VARCHAR(length=500),
               comment='Path to model artifact file (joblib/pickle)',
               existing_comment='Path to model artifact file (joblib)',
               existing_nullable=False)
    op.alter_column('model_registry', 'version',
               existing_type=sa.VARCHAR(length=50),
               comment='Model version identifier (timestamp or semantic version)',
               existing_comment='Model version (e.g., v1.0.0, 20241114_120000)',
               existing_nullable=False)
    op.alter_column('model_registry', 'model_name',
               existing_type=sa.VARCHAR(length=100),
               comment='Name of the ML model (e.g., distress_classifier, sale_probability)',
               existing_comment='Model name (e.g., distress_classifier, sale_probability)',
               existing_nullable=False)
    op.drop_column('model_registry', 'updated_at')
    op.drop_column('model_registry', 'created_at')
    op.drop_column('model_registry', 'description')
    op.drop_column('model_registry', 'deprecated_at')
    op.drop_column('model_registry', 'validation_metrics')
    op.drop_column('model_registry', 'training_samples')
    op.add_column('ml_feature_store', sa.Column('nearby_open_violations', sa.INTEGER(), autoincrement=False, nullable=True, comment='Number of nearby open violations'))
    op.add_column('ml_feature_store', sa.Column('nearby_violations', sa.INTEGER(), autoincrement=False, nullable=True, comment='Number of nearby violations from geo enrichment'))
    op.add_column('ml_feature_store', sa.Column('year_built', sa.INTEGER(), autoincrement=False, nullable=True, comment='Year property was built'))
    op.add_column('ml_feature_store', sa.Column('lot_size', sa.NUMERIC(precision=12, scale=2), autoincrement=False, nullable=True, comment='Lot size'))
    op.add_column('ml_feature_store', sa.Column('total_mkt', sa.NUMERIC(precision=12, scale=2), autoincrement=False, nullable=True, comment='Total market value'))
    op.add_column('ml_feature_store', sa.Column('living_area', sa.INTEGER(), autoincrement=False, nullable=True, comment='Living area in sqft'))
    op.add_column('ml_feature_store', sa.Column('equity_risk_ratio', sa.NUMERIC(precision=8, scale=4), autoincrement=False, nullable=True, comment='Equity to risk ratio'))
    op.add_column('ml_feature_store', sa.Column('distress_score', sa.NUMERIC(precision=5, scale=4), autoincrement=False, nullable=True, comment='Computed distress score'))
    op.add_column('ml_feature_store', sa.Column('has_tax_sale', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=False, comment='Has tax sale record'))
    op.add_column('ml_feature_store', sa.Column('tax_sale_deed_status', sa.VARCHAR(length=50), autoincrement=False, nullable=True, comment='Tax sale deed status'))
    op.add_column('ml_feature_store', sa.Column('taxes', sa.NUMERIC(precision=10, scale=2), autoincrement=False, nullable=True, comment='Annual taxes'))
    op.drop_constraint('uq_ml_features_parcel_time', 'ml_feature_store', type_='unique')
    op.drop_index('idx_ml_features_parcel', table_name='ml_feature_store')
    op.drop_index('idx_ml_features_has_outcome', table_name='ml_feature_store')
    op.drop_index('idx_ml_features_computed_at', table_name='ml_feature_store')
    op.create_unique_constraint(op.f('ml_feature_store_parcel_id_normalized_key'), 'ml_feature_store', ['parcel_id_normalized'], postgresql_nulls_not_distinct=False)
    op.create_index(op.f('idx_ml_feature_store_parcel'), 'ml_feature_store', ['parcel_id_normalized'], unique=False)
    op.create_index(op.f('idx_ml_feature_store_computed_at'), 'ml_feature_store', ['computed_at'], unique=False)
    op.alter_column('ml_feature_store', 'seed_type_code_violation',
               existing_type=sa.BOOLEAN(),
               server_default=sa.text('false'),
               comment=None,
               existing_comment='Is code violation seed',
               existing_nullable=False)
    op.alter_column('ml_feature_store', 'seed_type_foreclosure',
               existing_type=sa.BOOLEAN(),
               server_default=sa.text('false'),
               comment=None,
               existing_comment='Is foreclosure seed',
               existing_nullable=False)
    op.alter_column('ml_feature_store', 'seed_type_tax_sale',
               existing_type=sa.BOOLEAN(),
               server_default=sa.text('false'),
               comment=None,
               existing_comment='Is tax sale seed',
               existing_nullable=False)
    op.alter_column('ml_feature_store', 'property_age_years',
               existing_type=sa.INTEGER(),
               comment='Age of property in years',
               existing_comment='Property age in years',
               existing_nullable=True)
    op.alter_column('ml_feature_store', 'equity_percent',
               existing_type=sa.Numeric(precision=6, scale=2),
               type_=sa.NUMERIC(precision=5, scale=2),
               existing_comment='Equity percentage',
               existing_nullable=True)
    op.alter_column('ml_feature_store', 'open_violation_count',
               existing_type=sa.INTEGER(),
               comment='Number of open violations',
               existing_comment='Number of open/active violations',
               existing_nullable=True)
    op.alter_column('ml_feature_store', 'violation_count',
               existing_type=sa.INTEGER(),
               comment='Number of code violations',
               existing_comment='Total number of violations',
               existing_nullable=True)
    op.alter_column('ml_feature_store', 'computed_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When features were last computed',
               existing_comment='When features were computed',
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('ml_feature_store', 'parcel_id_normalized',
               existing_type=sa.VARCHAR(length=50),
               comment='Normalized parcel ID (digits only)',
               existing_comment='Normalized parcel ID',
               existing_nullable=False)
    op.drop_column('ml_feature_store', 'label_date')
    op.drop_column('ml_feature_store', 'actual_sale_price')
    op.drop_column('ml_feature_store', 'actual_distress_outcome')
    op.drop_column('ml_feature_store', 'nearest_violation_distance')
    op.drop_column('ml_feature_store', 'nearby_violations_count')
    op.drop_column('ml_feature_store', 'days_to_tax_sale')
    op.drop_column('ml_feature_store', 'tax_rate')
    op.drop_column('ml_feature_store', 'total_market_value')
    op.drop_column('ml_feature_store', 'max_violation_severity')
    op.drop_index('idx_lead_scores_tier_score', table_name='lead_scores', postgresql_ops={'total_score': 'DESC'})
    op.drop_index('idx_lead_scores_total_score', table_name='lead_scores', postgresql_ops={'total_score': 'DESC'})
    op.create_index(op.f('idx_lead_scores_total_score'), 'lead_scores', [sa.literal_column('total_score DESC')], unique=False)
    op.create_index(op.f('idx_lead_scores_priority_flag'), 'lead_scores', ['priority_flag'], unique=False)
    op.create_index(op.f('idx_lead_scores_ml_probability'), 'lead_scores', ['ml_probability'], unique=False)
    op.alter_column('lead_scores', 'priority_flag',
               existing_type=sa.BOOLEAN(),
               server_default=sa.text('false'),
               existing_comment='High priority flag from ML/hybrid scoring',
               existing_nullable=True)
    op.drop_column('lead_scores', 'ml_anomaly_score')
    op.drop_column('lead_scores', 'ml_cluster_id')
    op.drop_column('lead_scores', 'ml_risk_tier')
    op.drop_column('lead_scores', 'ml_risk_score')
    op.drop_column('lead_scores', 'profitability_details')
    op.drop_column('lead_scores', 'profitability_score')
    op.drop_index('idx_lead_score_history_snapshot_date', table_name='lead_score_history', postgresql_ops={'snapshot_date': 'DESC'})
    op.create_index(op.f('idx_lead_score_history_snapshot_date'), 'lead_score_history', [sa.literal_column('snapshot_date DESC')], unique=False)
    op.alter_column('enriched_seeds', 'processed',
               existing_type=sa.BOOLEAN(),
               server_default=sa.text('false'),
               existing_comment='Whether seed has been merged into properties table',
               existing_nullable=False)
    op.drop_index('idx_data_ingestion_runs_started_at', table_name='data_ingestion_runs', postgresql_ops={'started_at': 'DESC'})
    op.create_index(op.f('idx_data_ingestion_runs_started_at'), 'data_ingestion_runs', [sa.literal_column('started_at DESC')], unique=False)
    op.create_table('layer',
    sa.Column('topology_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('layer_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('schema_name', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('table_name', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('feature_column', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('feature_type', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('level', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.Column('child_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['topology_id'], ['topology.id'], name=op.f('layer_topology_id_fkey')),
    sa.PrimaryKeyConstraint('topology_id', 'layer_id', name=op.f('layer_pkey')),
    sa.UniqueConstraint('schema_name', 'table_name', 'feature_column', name=op.f('layer_schema_name_table_name_feature_column_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    op.create_table('spatial_ref_sys',
    sa.Column('srid', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('auth_name', sa.VARCHAR(length=256), autoincrement=False, nullable=True),
    sa.Column('auth_srid', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('srtext', sa.VARCHAR(length=2048), autoincrement=False, nullable=True),
    sa.Column('proj4text', sa.VARCHAR(length=2048), autoincrement=False, nullable=True),
    sa.CheckConstraint('srid > 0 AND srid <= 998999', name=op.f('spatial_ref_sys_srid_check')),
    sa.PrimaryKeyConstraint('srid', name=op.f('spatial_ref_sys_pkey'))
    )
    op.create_table('topology',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('name', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('srid', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('precision', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('hasz', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('topology_pkey')),
    sa.UniqueConstraint('name', name=op.f('topology_name_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    # ### end Alembic commands ###
